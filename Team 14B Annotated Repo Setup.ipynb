{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f66dba7b",
   "metadata": {},
   "source": [
    "# Team 14B — Stock Price Range Forecasting (GRU vs LSTM)\n",
    "_Auto‑annotated on 2025-08-14 16:22 UTC_\n",
    "\n",
  
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d5eb4c",
   "metadata": {},
   "source": [
    "## Contents\n",
    "- Overview\n",
    "- Setup\n",
    "- Data Loading & Preparation\n",
    "- Modeling (GRU & LSTM)\n",
    "- Training\n",
    "- Evaluation (MAE/RMSE)\n",
    "- Visualizations\n",
    "- Inference\n",
    "- Reproducibility Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8007567",
   "metadata": {
    "id": "-umNa44gjt60"
   },
   "source": [
    "# Time Series Forecasting Model\n",
    "Predict next day’s Open and Close prices\n",
    "\n",
    "Based on past N days of data for one company at a time\n",
    "Using a GRU or LSTM model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d14c514a",
   "metadata": {},
   "source": [
    "## Setup\n",
    "Imports, environment configuration, and utility definitions used across the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff6b3da",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 73
    },
    "id": "mB3UphJPjn2c",
    "outputId": "c9eb3885-d186-43bb-a276-6c63ae8d9bfb"
   },
   "outputs": [],
   "source": [
    "# === General setup / helpers ===\n",
    "from google.colab import files\n",
    "\n",
    "# Open a file upload dialog\n",
    "uploaded = files.upload()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70da344e",
   "metadata": {
    "id": "C_MA5U0Pj2t2"
   },
   "source": [
    "# **Importing neccessary libraries**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dac94b8",
   "metadata": {},
   "source": [
    "## Data Loading & Preparation\n",
    "Read OHLCV CSV(s), parse dates, sort chronologically, and generate sliding‑window sequences for supervised learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd592eff",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Zqvzziurj8RE",
    "outputId": "ba8e40b1-f7be-47f5-fe7e-242e29c83f37"
   },
   "outputs": [],
   "source": [
    "# === Datetime parsing and feature cleanup ===\n",
    "!pip install torchinfo\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec7421a",
   "metadata": {
    "id": "m_7HtjC8kCXY"
   },
   "source": [
    "**Saving Dataset to df**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c816464e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b4j3ZRoCkGg7",
    "outputId": "e829485c-1d92-4b02-c5fe-2f016305f69a"
   },
   "outputs": [],
   "source": [
    "# === Load data (CSV → DataFrame) ===\n",
    "df = pd.read_csv('World-Stock-Prices-Dataset.csv')\n",
    "head = df.head(10)\n",
    "print(f\"Top rows of dataset: {head}\")\n",
    "print(\"Nulls per column:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da29b84d",
   "metadata": {
    "id": "cFDwpD65pb0y"
   },
   "source": [
    "**Filter Data for One Company**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62121556",
   "metadata": {
    "id": "gFwEHH99plZd"
   },
   "outputs": [],
   "source": [
    "# === General setup / helpers ===\n",
    "df = df[df['Ticker'] == 'AAPL']  # Ticker for Amazon\n",
    "df = df.sort_values('Date')\n",
    "df = df[['Open', 'High', 'Low', 'Close', 'Volume']]  # Only needed columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a2e65c",
   "metadata": {
    "id": "5XgOkiy-pywj"
   },
   "source": [
    "# **Normalize the Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c546103d",
   "metadata": {
    "id": "SaJW2R60p5Li"
   },
   "outputs": [],
   "source": [
    "# === Feature scaling / normalization ===\n",
    "scaler = MinMaxScaler()\n",
    "scaled_data = scaler.fit_transform(df)\n",
    "\n",
    "# Convert back to DataFrame\n",
    "scaled_df = pd.DataFrame(scaled_data, columns=['Open', 'High', 'Low', 'Close', 'Volume'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db223844",
   "metadata": {
    "id": "JTVV9N7Ap8sg"
   },
   "source": [
    "#  Create Sequences (30 days → next day [Open, Close])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b1584f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NOY_292uqGlp",
    "outputId": "e69b2ea9-48d2-469e-b962-972f79e344dd"
   },
   "outputs": [],
   "source": [
    "# === General setup / helpers ===\n",
    "SEQ_LENGTH = 30\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "for i in range(SEQ_LENGTH, len(scaled_df)):\n",
    "    X.append(scaled_df.iloc[i-SEQ_LENGTH:i].values)\n",
    "    y.append(scaled_df.iloc[i][[0, 3]].values)  # Open and Close\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d8d88c6",
   "metadata": {
    "id": "1QVI21gpqJl3"
   },
   "source": [
    "**Create PyTorch Dataset**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b0d28f",
   "metadata": {},
   "source": [
    "## Modeling\n",
    "Define GRU and LSTM architectures with shared hyperparameters to ensure a fair comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "586ecd68",
   "metadata": {
    "id": "ePZYCaDSqPUT"
   },
   "outputs": [],
   "source": [
    "# === Helper classes / model definitions ===\n",
    "class StockDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "# Split data\n",
    "train_size = int(len(X) * 0.8)\n",
    "train_dataset = StockDataset(X[:train_size], y[:train_size])\n",
    "test_dataset = StockDataset(X[train_size:], y[train_size:])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a418d4b9",
   "metadata": {
    "id": "H1twd0PQqSzb"
   },
   "source": [
    "# Build GRU Model in PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b7eed8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1iQF3HswqZkY",
    "outputId": "db8ddf01-b1a6-44c5-b368-9c1b55723e32"
   },
   "outputs": [],
   "source": [
    "# === Define GRU model ===\n",
    "from torchinfo import summary\n",
    "class GRUModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
    "        super(GRUModel, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.gru = nn.GRU(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.gru(x)\n",
    "        out = out[:, -1, :]  # last timestep\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "model = GRUModel(input_size=5, hidden_size=64, num_layers=2, output_size=2)\n",
    "summary(model, input_size=(32, 30, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5929eb67",
   "metadata": {
    "id": "vXSP594rrAem"
   },
   "source": [
    "**Train the Model**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b9b7ce3",
   "metadata": {},
   "source": [
    "## Training\n",
    "Train models on the training set, monitor validation performance, and save artifacts (metrics/plots)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4179739b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SH2MVrGrrErp",
    "outputId": "f4ce4ceb-0ff3-447a-bd54-abf62e364d3d"
   },
   "outputs": [],
   "source": [
    "# === Training loop (loss, optimizer, backprop) ===\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs = 50\n",
    "model.train()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        output = model(X_batch)\n",
    "        loss = criterion(output, y_batch)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8053cd07",
   "metadata": {
    "id": "jhBx-wNHrOQ3"
   },
   "source": [
    "**Evaluate & Plot**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63112b3e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 442
    },
    "id": "ir_VTf7CrS96",
    "outputId": "059200e4-b147-4c35-f900-cacb68b4ab04"
   },
   "outputs": [],
   "source": [
    "# === Feature scaling / normalization ===\n",
    "from sklearn.metrics import mean_squared_error\n",
    "model.eval()\n",
    "predictions = []\n",
    "actuals = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for X_batch, y_batch in test_loader:\n",
    "        pred = model(X_batch)\n",
    "        predictions.append(pred.numpy().flatten())\n",
    "        actuals.append(y_batch.numpy().flatten())\n",
    "\n",
    "predictions = np.array(predictions)\n",
    "actuals = np.array(actuals)\n",
    "\n",
    "# Inverse transform to original scale\n",
    "# Fill dummy values for the other 3 features (High, Low, Volume)\n",
    "def rescale(preds_2col):\n",
    "    # preds_2col is shape [N, 2] → [Open, Close]\n",
    "    open_col = preds_2col[:, 0].reshape(-1, 1)\n",
    "    close_col = preds_2col[:, 1].reshape(-1, 1)\n",
    "    dummy = np.zeros((preds_2col.shape[0], 3))  # High, Low, Volume\n",
    "\n",
    "    # Reconstruct full 5-column input: [Open, High, Low, Close, Volume]\n",
    "    merged = np.hstack([open_col, dummy[:, 0:1], dummy[:, 1:2], close_col, dummy[:, 2:3]])\n",
    "    return scaler.inverse_transform(merged)[:, [0, 3]]  # Only get Open and Close\n",
    "\n",
    "# Apply to both actual and predicted\n",
    "pred_rescaled = rescale(predictions)\n",
    "actual_rescaled = rescale(actuals)\n",
    "\n",
    "# Calculate MSE\n",
    "mse_open = mean_squared_error(actual_rescaled[:, 0], pred_rescaled[:, 0])\n",
    "mse_close = mean_squared_error(actual_rescaled[:, 1], pred_rescaled[:, 1])\n",
    "print(f\"MSE for Open Price: {mse_open:.4f}\")\n",
    "print(f\"MSE for Close Price: {mse_close:.4f}\")\n",
    "\n",
    "#Plot\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.plot(actual_rescaled[:, 0], label='Actual Open', color='blue')\n",
    "plt.plot(pred_rescaled[:, 0], label='Predicted Open', color='orange')\n",
    "plt.plot(actual_rescaled[:, 1], label='Actual Close', color='green')\n",
    "plt.plot(pred_rescaled[:, 1], label='Predicted Close', color='red')\n",
    "plt.legend()\n",
    "plt.title(\"GRU Predicted vs Actual Stock Prices\")\n",
    "plt.xlabel(\"Days\")\n",
    "plt.ylabel(\"Price\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3785d95",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VQfu17ELhFS4",
    "outputId": "a661980c-acc8-477c-ff5b-74ceb99714cd"
   },
   "outputs": [],
   "source": [
    "# === General setup / helpers ===\n",
    "for i in range(5):\n",
    "    print(f\"Actual Open: {actual_rescaled[i,0]:.2f}, Pred Open: {pred_rescaled[i,0]:.2f} | \"\n",
    "          f\"Actual Close: {actual_rescaled[i,1]:.2f}, Pred Close: {pred_rescaled[i,1]:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04c7de95",
   "metadata": {
    "id": "qIqlegnl6vw1"
   },
   "source": [
    "**LSTM Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2b8550",
   "metadata": {
    "id": "qEHEePzU69ud"
   },
   "outputs": [],
   "source": [
    "# === Define LSTM model ===\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "\n",
    "        out, _ = self.lstm(x, (h0, c0))  # out: (batch, seq_len, hidden)\n",
    "        out = self.fc(out[:, -1, :])     # Take last output for prediction\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d0b707",
   "metadata": {
    "id": "YaoJ_-dx7TvO"
   },
   "source": [
    "**Train the Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c6dff42",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DtJg3vQz_r03",
    "outputId": "eb7adb1e-d87e-472a-deb1-4a06b2ba936e"
   },
   "outputs": [],
   "source": [
    "# === Training loop (loss, optimizer, backprop) ===\n",
    "# Initialize model\n",
    "lstm_model = LSTMModel(input_size=5, hidden_size=64, num_layers=2, output_size=2)\n",
    "\n",
    "# Define loss and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(lstm_model.parameters(), lr=0.001)\n",
    "\n",
    "# Train\n",
    "num_epochs = 50\n",
    "lstm_model.train()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        output = lstm_model(X_batch)\n",
    "        loss = criterion(output, y_batch)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(f\"[LSTM] Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2388cce1",
   "metadata": {
    "id": "nB3Ll3VgP21q"
   },
   "source": [
    "**Evaluate the LSTM Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f046416b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 433
    },
    "id": "5RG1sOeUP7qs",
    "outputId": "92bd9604-d2a4-4282-97fa-9217e5760fec"
   },
   "outputs": [],
   "source": [
    "# === Feature scaling / normalization ===\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "lstm_model.eval()\n",
    "predictions = []\n",
    "actuals = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for X_batch, y_batch in test_loader:\n",
    "        pred = lstm_model(X_batch)\n",
    "        predictions.append(pred.numpy().flatten())\n",
    "        actuals.append(y_batch.numpy().flatten())\n",
    "\n",
    "predictions = np.array(predictions)\n",
    "actuals = np.array(actuals)\n",
    "\n",
    "# Inverse transform to original scale\n",
    "def rescale(preds_2col):\n",
    "    # preds_2col is shape [N, 2] → [Open, Close]\n",
    "    open_col = preds_2col[:, 0].reshape(-1, 1)\n",
    "    close_col = preds_2col[:, 1].reshape(-1, 1)\n",
    "    dummy = np.zeros((preds_2col.shape[0], 3))  # High, Low, Volume\n",
    "\n",
    "    # Reconstruct full 5-column input: [Open, High, Low, Close, Volume]\n",
    "    merged = np.hstack([open_col, dummy[:, 0:1], dummy[:, 1:2], close_col, dummy[:, 2:3]])\n",
    "    return scaler.inverse_transform(merged)[:, [0, 3]]  # Only get Open and Close\n",
    "\n",
    "# Apply to both actual and predicted\n",
    "pred_rescaled = rescale(predictions)\n",
    "actual_rescaled = rescale(actuals)\n",
    "\n",
    "# Calculate MSE\n",
    "mse_open = mean_squared_error(actual_rescaled[:, 0], pred_rescaled[:, 0])\n",
    "mse_close = mean_squared_error(actual_rescaled[:, 1], pred_rescaled[:, 1])\n",
    "print(f\"MSE for Open Price: {mse_open:.4f}\")\n",
    "print(f\"MSE for Close Price: {mse_close:.4f}\")\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.plot(actual_rescaled[:, 0], label='Actual Open')\n",
    "plt.plot(pred_rescaled[:, 0], label='Predicted Open (LSTM)')\n",
    "plt.plot(actual_rescaled[:, 1], label='Actual Close')\n",
    "plt.plot(pred_rescaled[:, 1], label='Predicted Close (LSTM)')\n",
    "plt.legend()\n",
    "plt.title(\"LSTM Predicted vs Actual Stock Prices\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edcb2464",
   "metadata": {
    "id": "ul0q556KU4s3"
   },
   "source": [
    "**Comparing the GRU and LSTM models using Evaluation Metrics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d2c773",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qSI2dRoagV1a",
    "outputId": "2e18daa1-6a2c-4879-cffb-be5e48053b7b"
   },
   "outputs": [],
   "source": [
    "# === General setup / helpers ===\n",
    "for i in range(5):\n",
    "    print(f\"Actual Open: {actual_rescaled[i,0]:.2f}, Pred Open: {pred_rescaled[i,0]:.2f} | \"\n",
    "          f\"Actual Close: {actual_rescaled[i,1]:.2f}, Pred Close: {pred_rescaled[i,1]:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b99a78e",
   "metadata": {
    "id": "k607BjK5hpYM"
   },
   "source": [
    "**Saving the model to .pth**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8c910f",
   "metadata": {
    "id": "LNanqOpLiOs0"
   },
   "outputs": [],
   "source": [
    "# === General setup / helpers ===\n",
    "# Save the model weights (state_dict)\n",
    "torch.save(lstm_model.state_dict(), 'lstm_model_weights.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8472ac7",
   "metadata": {
    "id": "PKgP0XpOio2s"
   },
   "source": [
    "**Load the model later for deployment**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b467fb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qG42u4bCiqsV",
    "outputId": "c2995082-e81a-4f9c-c50a-c2f7710344bb"
   },
   "outputs": [],
   "source": [
    "# === Define LSTM model ===\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# First, re-import (or re-define) the model class you used during training\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(x)\n",
    "        out = self.fc(out[:, -1, :])  # Take the last time step output\n",
    "        return out\n",
    "\n",
    "# Model parameters (must match training)\n",
    "input_size = 5       # Open, High, Low, Close, Volume\n",
    "hidden_size = 64\n",
    "num_layers = 2\n",
    "output_size = 2      # Open & Close predictions\n",
    "\n",
    "# Recreate the model instance\n",
    "model = LSTMModel(input_size, hidden_size, num_layers, output_size)\n",
    "\n",
    "# Load trained weights\n",
    "model.load_state_dict(torch.load('lstm_model_weights.pth', map_location=torch.device('cpu')))\n",
    "model.eval()  # Set to evaluation mode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be867351",
   "metadata": {
    "id": "9geQO-7HjEWP"
   },
   "source": [
    "Save Scaler for Deployment\n",
    "\n",
    "After using MinMaxScaler or StandardScaler to normalize the data, we need need to save it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8e965f",
   "metadata": {
    "id": "GjOM8c16jE0t"
   },
   "outputs": [],
   "source": [
    "# === Feature scaling / normalization ===\n",
    "import joblib\n",
    "\n",
    "# Save the scaler\n",
    "joblib.dump(scaler, 'scaler.save')\n",
    "\n",
    "# Later load with:\n",
    "scaler = joblib.load('scaler.save')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b0cf5d",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "Compute MAE and RMSE on the test set and compare GRU vs LSTM."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "038a62c1",
   "metadata": {},
   "source": [
    "## Visualizations\n",
    "Plot learning curves and model comparison charts suitable for the repo’s `figures/`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afdae108",
   "metadata": {},
   "source": [
    "## Inference\n",
    "Run one‑off predictions given a recent CSV of candles."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81cacc34",
   "metadata": {},
   "source": [
    "## Reproducibility Notes\n",
    "- Set random seeds if needed.\n",
    "- Keep the same splits and scaling for both models.\n",
    "- Log versions (`pip freeze > requirements.txt`)."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
